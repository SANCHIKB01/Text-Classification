# -*- coding: utf-8 -*-
"""BIG_DATA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SyOm3Bqci0kQDIsOIp90dCOCndGVSYr5
"""

#!pip install pyspark
!pip install Spark

"""## ***Task***

• Predict if a patient is Hep or not based parameter

• The data set contains laboratory values of blood donors and Hepatitis C patients and demographic values like age
"""

# Load our Pkgs
from pyspark import SparkContext

#sc.stop()
sc = SparkContext(master='local[2]')

# Spark UI
sc

# Load Pkgs
from pyspark.sql import SparkSession

# Spark
spark = SparkSession.builder.appName("MLwithSpark").getOrCreate()

from google.colab import drive
drive.mount('/content/drive')

# Load our dataset
df = spark.read.csv("/content/drive/My Drive/hcvdata.csv", header=True, inferSchema=True)

# Preview Dataset
df.show()

# check for columns
print(df.columns)

# Rearrange
df = df.select('Age', 'Sex', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL','CREA', 'GGT', 'PROT','Category')

df.show(5)

# Check for datatypes
# Before InferSchema
df.dtypes

# Check for the Schema
df.printSchema()

# Descriptive summary
print(df.describe().show())

# Value Count
df.groupBy('Category').count().show()

"""# ***Feature Engineering***
+ Numberical Values
+ Vectorization
+ Scaling
"""

import pyspark.ml

dir(pyspark.ml)

# Load ML Pkgs
from pyspark.ml.feature import VectorAssembler,StringIndexer

df.show(4)

# Unique Values for Sex
df.select('Sex').distinct().show()

# Convert the string into numerical code
# label encoding
genderEncoder = StringIndexer(inputCol='Sex',outputCol='Gender').fit(df)

df = genderEncoder.transform(df)

df.show(5)

# Encoding for Category
# Label Encoding
catEncoder = StringIndexer(inputCol='Category',outputCol='Target').fit(df)
df = catEncoder.transform(df)

df.show(5)

# Get the labels
catEncoder.labels

# IndexToString
from pyspark.ml.feature import IndexToString

converter = IndexToString(inputCol='Target',outputCol='orig_cat')

converted_df = converter.transform(df)

converted_df.show()

### Feature
df.show()

print(df.columns)

df.dtypes

df2 = df.select('Age','Gender', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE','CHOL', 'CREA', 'GGT', 'PROT', 'Target')

df2.printSchema()

# df2.fillna(0,subset=['col1'])
df2 = df2.toPandas().replace('NA',0).astype(float)

type(df2)

type(df)

# Convert To PySpark Dataframe
new_df = spark.createDataFrame(df2)

new_df.show()

# Check For DTypes and Schema
new_df.printSchema()

required_features = ['Age','Gender', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE','CHOL', 'CREA', 'GGT', 'PROT', 'Target']

# VectorAsm
vec_assembler =VectorAssembler(inputCols = required_features, outputCol = 'features')

vec_df = vec_assembler.transform(new_df)

vec_df.show(5)

#Train, test, split
train_df,test_df = vec_df.randomSplit([0.7,0.3])

train_df.count()

train_df.show(4)

"""## ***Model Building***
+ Pyspark.ml: DataFrame
+ Pyspark.mllib: RDD /Legacy

"""

from pyspark.ml.classification import LogisticRegression,DecisionTreeClassifier

# Logist Model
lr = LogisticRegression(featuresCol='features',labelCol='Target')

lr_model = lr.fit(train_df)

y_pred = lr_model.transform(test_df)

y_pred.show()

print(y_pred.columns)

y_pred.select('target','rawPrediction', 'probability', 'prediction').show()

"""# ***Model Evaluation***"""

from pyspark.ml.evaluation import MulticlassClassificationEvaluator

# How to Check For Accuracy
multi_evaluator = MulticlassClassificationEvaluator(labelCol='Target',metricName='accuracy')

multi_evaluator.evaluate(y_pred)

from pyspark.mllib.evaluation import MulticlassMetrics

lr_metric = MulticlassMetrics(y_pred['target', 'prediction'].rdd)

dir(lr_metric)

print("Accuracy",lr_metric.accuracy)

print("Precision",lr_metric.precision(1.0))
print("Recall",lr_metric.recall(1.0))
print("F1Score",lr_metric.fMeasure(1.0))

dir(lr_model)